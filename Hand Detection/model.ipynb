{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'dataset/train'\n",
    "valid_path = 'dataset/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8438 images belonging to 2 classes.\n",
      "Found 3051 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['hand','not_hand'], batch_size = 10)\n",
    "valid_batch = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['hand','not_hand'], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    cnn.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in cnn.layers:\n",
    "    layer.trainable = False\n",
    "cnn.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 132s 166ms/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0120 - val_acc: 0.9970\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 96s 120ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 96s 119ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0116 - val_acc: 0.9980\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 0.0109 - acc: 0.9977 - val_loss: 0.0049 - val_acc: 0.9990\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 3.3338e-04 - acc: 0.9997 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 8.0176e-07 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 1.3211e-06 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 8.0066e-07 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 9.2164e-07 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 95s 119ms/step - loss: 5.9900e-07 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1f90a1320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit_generator(train_batch, steps_per_epoch = 800, epochs = 10,\n",
    "               validation_data = valid_batch, validation_steps = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = image.load_img('333.jpg', target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = cnn.predict_classes(x, batch_size=10, verbose = 1)\n",
    "# print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.740948e-20 1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('111.jpg').resize((224,224))\n",
    "x = np.array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "classes = cnn.predict(x)\n",
    "print(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
